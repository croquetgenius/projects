{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data from NLP\n",
    "df = pd.read_csv('./data/python1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   python       2000 non-null   int64  \n",
      " 1   selftext     1226 non-null   object \n",
      " 2   title        2000 non-null   object \n",
      " 3   self_pol     2000 non-null   float64\n",
      " 4   self_sub     2000 non-null   float64\n",
      " 5   title_pol    2000 non-null   float64\n",
      " 6   title_sub    2000 non-null   float64\n",
      " 7   title_words  2000 non-null   float64\n",
      " 8   self_words   2000 non-null   float64\n",
      " 9   words        2000 non-null   float64\n",
      " 10  sentences    2000 non-null   float64\n",
      " 11  text_pol     2000 non-null   float64\n",
      " 12  text_sub     2000 non-null   float64\n",
      " 13  text         2000 non-null   object \n",
      "dtypes: float64(10), int64(1), object(3)\n",
      "memory usage: 218.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# reminder of what the data looks like\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression(CVEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X, y for modeling\n",
    "X = df['text']\n",
    "y = df['python']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTS with random state so all models use the same splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline with vectorizer to tokenize and vectorize, will model with LogisticRegression\n",
    "lr_cvec_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression(n_jobs=-1))\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns out the default params work best\n",
    "params = {\n",
    "#     'cvec__stop_words': [None, 'english'],\n",
    "#     'cvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "#     'cvec__min_df': [2, 3],\n",
    "#     'cvec__max_df': [.9, .95],\n",
    "#     'cvec__ngram_range': [(1,1), (1,2)]\n",
    "    'lr__C':np.linspace(0.1, 1, 20),\n",
    "    'lr__solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run gridsearch to tune hyperparameters\n",
    "gs = GridSearchCV(lr_cvec_pipe, param_grid=params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mackmcgowen/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Users/mackmcgowen/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('lr', LogisticRegression(n_jobs=-1))]),\n",
       "             param_grid={'lr__C': array([0.1       , 0.14736842, 0.19473684, 0.24210526, 0.28947368,\n",
       "       0.33684211, 0.38421053, 0.43157895, 0.47894737, 0.52631579,\n",
       "       0.57368421, 0.62105263, 0.66842105, 0.71578947, 0.76315789,\n",
       "       0.81052632, 0.85789474, 0.90526316, 0.95263158, 1.        ]),\n",
       "                         'lr__solver': ['newton-cg', 'lbfgs', 'liblinear',\n",
       "                                        'sag', 'saga']})"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit training data on best model\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                ('lr',\n",
       "                 LogisticRegression(C=0.7631578947368421, n_jobs=-1,\n",
       "                                    solver='sag'))])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.936"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get best score for\n",
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.864"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8733333333333333"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr_cvec_pipe, X_train, y_train, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.842"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr_cvec_pipe, X_test, y_test, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## Model appears to be a little overfit, could probably bring the variance down but I'm going to use voting classifier so I'm short on time and hopefully the variance is worked out by voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression(TFID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['python']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as lr_cvec_pipe, except we are using TfidVectorizer instead of CountVectorizer.\n",
    "lr_tfid_pipe = Pipeline([\n",
    "    ('tfid', TfidfVectorizer(max_features=5000, min_df=2, max_df=.7, ngram_range=(1,2))),\n",
    "    ('lr', LogisticRegression(solver='newton-cg',n_jobs=-1))\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do Not run, already tuned hyperparameters\n",
    "params = {\n",
    "#     'tfid__stop_words': [None, 'english'],\n",
    "#     'tfid__max_features': [5000, 5500],\n",
    "#     'tfid__min_df': [2],\n",
    "#     'tfid__max_df': [.7, .65, .6,],\n",
    "#     'tfid__ngram_range': [(1,3), (1,2)]\n",
    "#     'lr__C':np.linspace(0.1, 1, 20),\n",
    "#     'lr__solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(lr_tfid_pipe, param_grid=params, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mackmcgowen/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Users/mackmcgowen/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Users/mackmcgowen/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Users/mackmcgowen/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/Users/mackmcgowen/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tfid',\n",
       "                                        TfidfVectorizer(max_df=0.7,\n",
       "                                                        max_features=5000,\n",
       "                                                        min_df=2,\n",
       "                                                        ngram_range=(1, 2))),\n",
       "                                       ('lr', LogisticRegression(n_jobs=-1))]),\n",
       "             param_grid={'lr__C': array([0.1       , 0.14736842, 0.19473684, 0.24210526, 0.28947368,\n",
       "       0.33684211, 0.38421053, 0.43157895, 0.47894737, 0.52631579,\n",
       "       0.57368421, 0.62105263, 0.66842105, 0.71578947, 0.76315789,\n",
       "       0.81052632, 0.85789474, 0.90526316, 0.95263158, 1.        ]),\n",
       "                         'lr__solver': ['newton-cg', 'lbfgs', 'liblinear',\n",
       "                                        'sag', 'saga']})"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit training data\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfid',\n",
       "                 TfidfVectorizer(max_df=0.7, max_features=5000, min_df=2,\n",
       "                                 ngram_range=(1, 2))),\n",
       "                ('lr',\n",
       "                 LogisticRegression(C=0.9052631578947369, n_jobs=-1,\n",
       "                                    solver='newton-cg'))])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9773333333333334"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.886"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8960000000000001"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr_tfid_pipe, X_train, y_train, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr_tfid_pipe, X_test, y_test, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## Just like the other Logistic Regression model, this one appears to be a little overfit, could probably bring the variance down but I'm going to use voting classifier so I'm short on time and hopefully the variance is worked out by voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier(CVEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['python']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as lr_cvec_pipe, except we are using a RandomForest Classifier and CountVectorizer.\n",
    "rf_cvec_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(max_features=4000, min_df=3, max_df=.9)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=128, max_depth=9,n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do NOT run, over 5000 models so I ran it once using my own linux server. Got best params from there.\n",
    "# params = {\n",
    "#     'rf__n_estimators':[126,127,128],\n",
    "#     'rf__max_features':[None, 'auto'],\n",
    "#     'rf__max_depth':[7,8,9],\n",
    "#     'cvec__stop_words': [None, 'english'],\n",
    "#     'cvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "#     'cvec__min_df': [2, 3],\n",
    "#     'cvec__max_df': [.9, .95],\n",
    "#     'cvec__ngram_range': [(1,1), (1,2)]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec',\n",
       "                 CountVectorizer(max_df=0.9, max_features=4000, min_df=3)),\n",
       "                ('rf',\n",
       "                 RandomForestClassifier(max_depth=9, n_estimators=128,\n",
       "                                        n_jobs=-1))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cvec_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8466666666666667"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rf_cvec_pipe, X_train, y_train, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.844"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rf_cvec_pipe, X_test, y_test, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## Unlike the LogisticRegression models, this one is not overfit, the variance is minimal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier(TFID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['python']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as lr_cvec_pipe, except we are using a RandomForest Classifier and TfidVectorizer.\n",
    "rf_tfid_pipe = Pipeline([\n",
    "    ('tfid', TfidfVectorizer(max_features=4000, min_df=3, max_df=.9)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=128, max_depth=9,n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do NOT run, over 5000 models so I ran it once using my own linux server. Got best params from there.\n",
    "# params = {\n",
    "#     'rf__n_estimators':[126,127,128],\n",
    "#     'rf__max_features':[None, 'auto'],\n",
    "#     'rf__max_depth':[7,8,9],\n",
    "#     'cvec__stop_words': [None, 'english'],\n",
    "#     'cvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "#     'cvec__min_df': [2, 3],\n",
    "#     'cvec__max_df': [.9, .95],\n",
    "#     'cvec__ngram_range': [(1,1), (1,2)]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfid',\n",
       "                 TfidfVectorizer(max_df=0.9, max_features=4000, min_df=3)),\n",
       "                ('rf',\n",
       "                 RandomForestClassifier(max_depth=9, n_estimators=128,\n",
       "                                        n_jobs=-1))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_tfid_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9373333333333334"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_tfid_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8626666666666667"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rf_tfid_pipe, X_train, y_train, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.832"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_tfid_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8160000000000001"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rf_tfid_pipe, X_test, y_test, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## Like the other RandomForest model, this one is not overfit, the variance is minimal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MN Naive Bayes(CVEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['python']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as lr_cvec_pipe, except we are using a Naive Bayes Classifier and CountVectorizer.\n",
    "nb_cvec_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(max_features=4000, min_df=3, max_df=.9)),\n",
    "    ('rf', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec',\n",
       "                 CountVectorizer(max_df=0.9, max_features=4000, min_df=3)),\n",
       "                ('rf', MultinomialNB())])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_cvec_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.932"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_cvec_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_cvec_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8733333333333333"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(nb_cvec_pipe, X_train, y_train, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8019999999999999"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(nb_cvec_pipe, X_test, y_test, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## Just like the Logistic Regression models, this one appears to be a little overfit, could probably bring the variance down but I'm going to use voting classifier so I'm short on time and hopefully the variance is worked out by voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MN Naive Bayes(TFID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['python']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as lr_cvec_pipe, except we are using a Naive Bayes Classifier and TfidVectorizer.\n",
    "nb_tfid_pipe = Pipeline([\n",
    "    ('tfid', TfidfVectorizer(max_features=4000, min_df=3, max_df=.9)),\n",
    "    ('rf', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfid',\n",
       "                 TfidfVectorizer(max_df=0.9, max_features=4000, min_df=3)),\n",
       "                ('rf', MultinomialNB())])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_tfid_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473333333333334"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_tfid_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_tfid_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8626666666666667"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(nb_tfid_pipe, X_train, y_train, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.842"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(nb_tfid_pipe, X_test, y_test, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## Unlike the other Naive Bayes model, this one appears to not be overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">### Instantiating a VotingClassifier which uses all of our previous models and has them vote on the correct classification. There are two options, a 'hard' vote and a 'soft' vote. I borrowed some code from sklearn's documentation on VotingClassifiers. https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting = 'hard'\n",
    "vote_hard = VotingClassifier(estimators=[('lr_cvec', lr_cvec_pipe), ('lr_tfid', lr_tfid_pipe), ('rf_cvec', rf_cvec_pipe), ('rf_tfid', rf_tfid_pipe), \n",
    "                                    ('nb_cvec', nb_cvec_pipe), ('nb_tfid', nb_tfid_pipe)], n_jobs=-1, voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.87 (+/- 0.02) [Logistic Regression(CVEC)]\n",
      "Training Accuracy: 0.90 (+/- 0.03) [Logistic Regression(TFID)]\n",
      "Training Accuracy: 0.86 (+/- 0.02) [Random Forest(CVEC)]\n",
      "Training Accuracy: 0.85 (+/- 0.03) [Random Forest(TFID)]\n",
      "Training Accuracy: 0.87 (+/- 0.02) [Naive Bayes(CVEC)]\n",
      "Training Accuracy: 0.86 (+/- 0.02) [Naive Bayes(TFID)]\n",
      "Training Accuracy: 0.90 (+/- 0.03) [Ensemble]\n",
      "\n",
      "Testing Accuracy: 0.84 (+/- 0.04) [Logistic Regression(CVEC)]\n",
      "Testing Accuracy: 0.85 (+/- 0.02) [Logistic Regression(TFID)]\n",
      "Testing Accuracy: 0.84 (+/- 0.03) [Random Forest(CVEC)]\n",
      "Testing Accuracy: 0.82 (+/- 0.03) [Random Forest(TFID)]\n",
      "Testing Accuracy: 0.80 (+/- 0.03) [Naive Bayes(CVEC)]\n",
      "Testing Accuracy: 0.84 (+/- 0.02) [Naive Bayes(TFID)]\n",
      "Testing Accuracy: 0.85 (+/- 0.02) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "# voting = 'hard'\n",
    "# the models are zipped into tuples of (model, 'name')\n",
    "# iterate through tuples and for each model, we are printing the cross_val_score on training data\n",
    "# for loop code from https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier\n",
    "for clf, label in zip([lr_cvec_pipe, lr_tfid_pipe, rf_cvec_pipe, rf_tfid_pipe, nb_cvec_pipe, nb_tfid_pipe, vote_hard], \n",
    "                      ['Logistic Regression(CVEC)','Logistic Regression(TFID)', 'Random Forest(CVEC)',\n",
    "                       'Random Forest(TFID)', 'Naive Bayes(CVEC)', 'Naive Bayes(TFID)', 'Ensemble']):\n",
    "    train_scores = cross_val_score(clf, X_train, y_train, scoring='accuracy', cv=5)\n",
    "    print(\"Training Accuracy: %0.2f (+/- %0.2f) [%s]\" % (train_scores.mean(), train_scores.std(), label))\n",
    "    \n",
    "print('') # print line for space\n",
    "    \n",
    "for clf, label in zip([lr_cvec_pipe, lr_tfid_pipe, rf_cvec_pipe, rf_tfid_pipe, nb_cvec_pipe, nb_tfid_pipe, vote_hard], \n",
    "                      ['Logistic Regression(CVEC)','Logistic Regression(TFID)', 'Random Forest(CVEC)',\n",
    "                       'Random Forest(TFID)', 'Naive Bayes(CVEC)', 'Naive Bayes(TFID)', 'Ensemble']):\n",
    "    test_scores = cross_val_score(clf, X_test, y_test, scoring='accuracy', cv=5)\n",
    "    print(\"Testing Accuracy: %0.2f (+/- %0.2f) [%s]\" % (test_scores.mean(), test_scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## As you can see, the Ensemble model with 'hard' voting was no better than the Logistic Regression(TFID) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_soft = VotingClassifier(estimators=[('lr_cvec', lr_cvec_pipe), ('lr_tfid', lr_tfid_pipe), ('rf_cvec', rf_cvec_pipe), ('rf_tfid', rf_tfid_pipe), \n",
    "                                    ('nb_cvec', nb_cvec_pipe), ('nb_tfid', nb_tfid_pipe)], n_jobs=-1, voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.87 (+/- 0.02) [Logistic Regression(CVEC)]\n",
      "Training Accuracy: 0.90 (+/- 0.03) [Logistic Regression(TFID)]\n",
      "Training Accuracy: 0.86 (+/- 0.03) [Random Forest(CVEC)]\n",
      "Training Accuracy: 0.86 (+/- 0.03) [Random Forest(TFID)]\n",
      "Training Accuracy: 0.87 (+/- 0.02) [Naive Bayes(CVEC)]\n",
      "Training Accuracy: 0.86 (+/- 0.02) [Naive Bayes(TFID)]\n",
      "Training Accuracy: 0.90 (+/- 0.03) [Ensemble]\n",
      "\n",
      "Testing Accuracy: 0.84 (+/- 0.04) [Logistic Regression(CVEC)]\n",
      "Testing Accuracy: 0.85 (+/- 0.02) [Logistic Regression(TFID)]\n",
      "Testing Accuracy: 0.83 (+/- 0.02) [Random Forest(CVEC)]\n",
      "Testing Accuracy: 0.82 (+/- 0.04) [Random Forest(TFID)]\n",
      "Testing Accuracy: 0.80 (+/- 0.03) [Naive Bayes(CVEC)]\n",
      "Testing Accuracy: 0.84 (+/- 0.02) [Naive Bayes(TFID)]\n",
      "Testing Accuracy: 0.86 (+/- 0.03) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "# voting = 'soft'\n",
    "# the models are zipped into tuples of (model, 'name')\n",
    "# iterate through tuples and for each model, we are printing the cross_val_score on training data\n",
    "# for loop code from https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier\n",
    "for clf, label in zip([lr_cvec_pipe, lr_tfid_pipe, rf_cvec_pipe, rf_tfid_pipe, nb_cvec_pipe, nb_tfid_pipe, vote_soft], \n",
    "                      ['Logistic Regression(CVEC)','Logistic Regression(TFID)', 'Random Forest(CVEC)',\n",
    "                       'Random Forest(TFID)', 'Naive Bayes(CVEC)', 'Naive Bayes(TFID)', 'Ensemble']):\n",
    "    train_scores = cross_val_score(clf, X_train, y_train, scoring='accuracy', cv=5)\n",
    "    print(\"Training Accuracy: %0.2f (+/- %0.2f) [%s]\" % (train_scores.mean(), train_scores.std(), label))\n",
    "    \n",
    "print('') # print line for space\n",
    "\n",
    "vote_soft = VotingClassifier(estimators=[('lr_cvec', lr_cvec_pipe), ('lr_tfid', lr_tfid_pipe), ('rf_cvec', rf_cvec_pipe), ('rf_tfid', rf_tfid_pipe), \n",
    "                                    ('nb_cvec', nb_cvec_pipe), ('nb_tfid', nb_tfid_pipe)], n_jobs=-1, voting='soft')\n",
    "# voting = 'soft'\n",
    "for clf, label in zip([lr_cvec_pipe, lr_tfid_pipe, rf_cvec_pipe, rf_tfid_pipe, nb_cvec_pipe, nb_tfid_pipe, vote_soft], \n",
    "                      ['Logistic Regression(CVEC)','Logistic Regression(TFID)', 'Random Forest(CVEC)',\n",
    "                       'Random Forest(TFID)', 'Naive Bayes(CVEC)', 'Naive Bayes(TFID)', 'Ensemble']):\n",
    "    test_scores = cross_val_score(clf, X_test, y_test, scoring='accuracy', cv=5)\n",
    "    print(\"Testing Accuracy: %0.2f (+/- %0.2f) [%s]\" % (test_scores.mean(), test_scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">## As you can see, the Ensemble model with 'soft' voting was marginally better on testing data than the other models, though still falling within std."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Key terms for each language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from one of the pipelines, take the feature_importances and feature_names so we can pair them to find key words\n",
    "imp = rf_cvec_pipe['rf'].feature_importances_\n",
    "features = rf_cvec_pipe['cvec'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip them together into a dictionary so we can sort, then iterate through\n",
    "data = dict(zip(features, imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the data, choose top 100, store as key_terms\n",
    "key_terms = sorted(data, key=data.get, reverse=True)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate Counter method on key_terms to make a dictionary of key_terms\n",
    "c = Counter(key_terms)\n",
    "# combine, then tokenize the entire text of the python class\n",
    "python_words = df.loc[df.python == 1].text.str.cat(sep=(','))\n",
    "python_words = python_words.split(' ')\n",
    "python_words = ' '.join(python_words).split()\n",
    "# iterate through words in python class, match with key_words and add to the counter\n",
    "for i in python_words:\n",
    "    if i in c.keys():\n",
    "        c[i] += 1\n",
    "    python_terms = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe from dictionary and save for use in visualizations\n",
    "python_terms_df = pd.DataFrame(python_terms.items(), columns=['Term','Count'])\n",
    "\n",
    "# python_terms_df.to_csv('./data/python_terms.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate Counter method on key_terms to make a dictionary of key_terms\n",
    "c = Counter(key_terms)\n",
    "# combine, then tokenize the entire text of the go class\n",
    "go_words = df.loc[df.python == 0].text.str.cat(sep=(','))\n",
    "go_words = go_words.split(' ')\n",
    "go_words = ' '.join(go_words).split()\n",
    "# iterate through words in go class, match with key_words and add to the counter\n",
    "for i in go_words:\n",
    "    if i in c.keys():\n",
    "        c[i] += 1\n",
    "    go_terms = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe from dictionary and save for use in visualizations\n",
    "go_terms_df = pd.DataFrame(go_terms.items(), columns=['Term','Count'])\n",
    "\n",
    "# go_terms_df.to_csv('./data/go_terms.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the dataframes into one to use for visualizations\n",
    "\n",
    "python_terms_df['python'] = 1\n",
    "go_terms_df['python'] = 0\n",
    "\n",
    "terms_df = python_terms_df.append(go_terms_df)\n",
    "\n",
    "# terms_df.to_csv('./data/terms.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>self_pol</th>\n",
       "      <th>self_sub</th>\n",
       "      <th>title_pol</th>\n",
       "      <th>title_sub</th>\n",
       "      <th>title_words</th>\n",
       "      <th>self_words</th>\n",
       "      <th>words</th>\n",
       "      <th>sentences</th>\n",
       "      <th>text_pol</th>\n",
       "      <th>text_sub</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055741</td>\n",
       "      <td>0.208771</td>\n",
       "      <td>0.067945</td>\n",
       "      <td>0.187181</td>\n",
       "      <td>8.664</td>\n",
       "      <td>52.511</td>\n",
       "      <td>61.175</td>\n",
       "      <td>2.630</td>\n",
       "      <td>0.096280</td>\n",
       "      <td>0.314685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.045397</td>\n",
       "      <td>0.186743</td>\n",
       "      <td>0.041154</td>\n",
       "      <td>0.205864</td>\n",
       "      <td>10.105</td>\n",
       "      <td>52.807</td>\n",
       "      <td>62.912</td>\n",
       "      <td>2.667</td>\n",
       "      <td>0.076247</td>\n",
       "      <td>0.321351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        self_pol  self_sub  title_pol  title_sub  title_words  self_words  \\\n",
       "python                                                                      \n",
       "0       0.055741  0.208771   0.067945   0.187181        8.664      52.511   \n",
       "1       0.045397  0.186743   0.041154   0.205864       10.105      52.807   \n",
       "\n",
       "         words  sentences  text_pol  text_sub  \n",
       "python                                         \n",
       "0       61.175      2.630  0.096280  0.314685  \n",
       "1       62.912      2.667  0.076247  0.321351  "
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('python').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
